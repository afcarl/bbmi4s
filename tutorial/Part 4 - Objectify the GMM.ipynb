{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Objectify\" the Gaussian Mixture Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Distribution(object):\n",
    "    \"\"\"\n",
    "    A distribution supports a few operations:\n",
    "      - it contains the value of the parameters (e.g. mean of the Gaussian)\n",
    "      - it also has hyperparameters that specify priors on the parameters\n",
    "      - it allows you to sample random variables\n",
    "      - it computes the log likelihood of a set of data points\n",
    "    \"\"\"\n",
    "    \n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def rvs(self, size=1):\n",
    "        \"\"\"\n",
    "        Generate 'size' number of random variables from the dist.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def log_likelihood(self, X):\n",
    "        \"\"\"\n",
    "        Compute the log likelihood of X.\n",
    "        \"\"\"\n",
    "        pass  \n",
    "    \n",
    "\n",
    "class GibbsSampling(object):\n",
    "    \"\"\"\n",
    "    Define an interface for any distribution that \n",
    "    supports Gibbs sampling.\n",
    "    \"\"\"\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def resample(self, X):\n",
    "        \"\"\"\n",
    "        Take in a set of observed datapoints and \n",
    "        update the parameters with a draw from their\n",
    "        conditional distribution.\n",
    "        \n",
    "        :param X: NxD matrix, where D is the dimensionality \n",
    "                  of the rv's this distribution generates\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gaussian(Distribution, GibbsSampling):\n",
    "    \"\"\"\n",
    "    Gaussian is parameterized by a mean parameter; \n",
    "    let's assume that the variance is fixed for now. \n",
    "    \n",
    "    x ~ N(mu, sigma^2)\n",
    "    mu ~ N(mu_0, eta_0^2)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, mu=None, sigmasq=1.0, mu_0=1.0, etasq_0=1.0):\n",
    "        # Hyperparameters\n",
    "        self.mu_0 = mu_0\n",
    "        self.etasq_0 = etasq_0\n",
    "        self.sigmasq = sigmasq\n",
    "        \n",
    "        # If mu is given, use it, otherwise sample prior\n",
    "        if mu is not None:\n",
    "            self.mu = mu\n",
    "        else:\n",
    "            self.resample(np.array([]))\n",
    "        \n",
    "    def rvs(self, size=1):\n",
    "        \"\"\"\n",
    "        Sample x for given mu and sigma^2\n",
    "        \"\"\"\n",
    "        return npr.normal(self.mu, np.sqrt(self.sigmasq), size=size)\n",
    "        \n",
    "    def log_likelihood(self, X):\n",
    "        \"\"\"\n",
    "        Log likelihood, log p(x | mu, sigma^2)\n",
    "        \n",
    "        :param X: is N x 1 vector \n",
    "        \"\"\"\n",
    "        m, v = self.mu, self.sigmasq\n",
    "        return -1./2 * np.log(2*np.pi*v)  -1./2 * (X-m)**2 / v\n",
    "    \n",
    "    def get_statistics(self, X):\n",
    "        \"\"\"\n",
    "        Extract sufficient statistics of X for resampling.\n",
    "        \"\"\"\n",
    "        M = X.shape[0]\n",
    "        S = X.sum(axis=0)\n",
    "        return M, S\n",
    "    \n",
    "    def resample(self, X):\n",
    "        \"\"\"\n",
    "        Sample a new mean given the observed datapoints X\n",
    "        and the prior, defined by mu_0 and eta^2_0\n",
    "        \"\"\"\n",
    "        # Allow X to be a vector \n",
    "        X = X[:,None] if X.ndim == 1 else X\n",
    "        assert X.shape[1] == 1\n",
    "        \n",
    "        # TODO: Write this in terms of \"natural parameters\"\n",
    "        stats = self.get_statistics(X)\n",
    "        v = 1./(1./self.etasq_0 + stats[0]/self.sigmasq)\n",
    "        m = v * (self.mu_0/self.etasq_0 + stats[1]/self.sigmasq)\n",
    "        \n",
    "        # Sample from the conditional normal distribution\n",
    "        self.mu = npr.normal(m, np.sqrt(v))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True mean: 0.00\n",
      "Initial Test mean: -1.70\n",
      "Final Test mean: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Simple test. Generate from one Gaussian and resample another.\n",
    "g_true = Gaussian(mu=0.0, sigmasq=1.0, mu_0=0., etasq_0=2.0)\n",
    "g_test = Gaussian(sigmasq=1.0, mu_0=0., etasq_0=2.0)\n",
    "\n",
    "# Generate data from a Gaussian with mean 2 and then resample\n",
    "print(\"True mean: {0:.2f}\".format(g_true.mu))\n",
    "print(\"Initial Test mean: {0:.2f}\".format(g_test.mu))\n",
    "X = g_true.rvs(size=1000)\n",
    "\n",
    "# Resample the test mean given X\n",
    "g_test.resample(X)\n",
    "print(\"Final Test mean: {0:.2f}\".format(g_test.mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Categorical(Distribution, GibbsSampling):\n",
    "    \"\"\"\n",
    "    x ~ Cat(pi);   pi=[0,1]^K and \\sum_k pi_k = 1\n",
    "    pi ~ Dir(alpha)\n",
    "    \"\"\"\n",
    "    def __init__(self, K, pi=None, alpha=1.0):\n",
    "        # Hyperparameters\n",
    "        self.K = K\n",
    "        self.alpha = alpha * np.ones(K)\n",
    "        \n",
    "        # If mu is given, use it, otherwise sample prior\n",
    "        if pi is not None:\n",
    "            self.pi = pi\n",
    "        else:\n",
    "            self.resample(np.array([]))\n",
    "        \n",
    "    def rvs(self, size=1):\n",
    "        \"\"\"\n",
    "        Sample x for given pi. Return 'size' rolls of K-sided die.\n",
    "        \"\"\"\n",
    "        return npr.choice(self.K, p=self.pi, size=size)\n",
    "        \n",
    "    def log_likelihood(self, X):\n",
    "        \"\"\"\n",
    "        Log likelihood, log p(X | pi)\n",
    "        \n",
    "        :param X: is N x 1 vector \n",
    "        \"\"\"\n",
    "        assert X.dtype == int\n",
    "        lp += np.log(self.pi[X])\n",
    "        \n",
    "    def get_statistics(self, X):\n",
    "        \"\"\"\n",
    "        Extract sufficient statistics of X for resampling.\n",
    "        \"\"\"\n",
    "        X = X.astype(int)\n",
    "        M = np.bincount(X, minlength=self.K)\n",
    "        return (M,)\n",
    "    \n",
    "    def resample(self, X):\n",
    "        \"\"\"\n",
    "        Sample a new mean given the observed datapoints X\n",
    "        and the prior, defined by mu_0 and eta^2_0\n",
    "        \"\"\"\n",
    "        stats = self.get_statistics(X)\n",
    "        self.pi = npr.dirichlet(self.alpha + stats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True pi:  [ 0.307  0.028  0.191  0.022  0.298  0.154]\n",
      "Initial Test pi:  [ 0.049  0.048  0.336  0.184  0.376  0.007]\n",
      "Final Test pi:  [ 0.321  0.022  0.206  0.009  0.301  0.141]\n"
     ]
    }
   ],
   "source": [
    "# Simple test: generate from one categorical and resample another\n",
    "c_true = Categorical(K=6, alpha=1.0)\n",
    "c_test = Categorical(K=6, alpha=1.0)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print(\"True pi: \", c_true.pi)\n",
    "print(\"Initial Test pi: \", c_test.pi)\n",
    "\n",
    "X = c_true.rvs(size=1000)\n",
    "\n",
    "c_test.resample(X)\n",
    "print(\"Final Test pi: \", c_test.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a Labels class that contains the \n",
    "# class assignments for each datapoint.\n",
    "# This won't be a proper distribution, but \n",
    "# it will suffice. \n",
    "class Labels(object):\n",
    "    def __init__(X, K, mixture_distns, prior_distn):\n",
    "        \"\"\"\n",
    "        :param X:  The Nx1 dataset of Gaussian observations\n",
    "        :param K:  The number of classes\n",
    "        \n",
    "        :param mixture_distns: A list of K Distribution objects\n",
    "        :param prior_distn:    A Categorical Distribution object\n",
    "        \"\"\"\n",
    "        # Store the data\n",
    "        self.X, self.K = X, K\n",
    "        self.N = X.shape[0]\n",
    "        \n",
    "        # Store the distributions\n",
    "        assert len(mixture_distns) == K\n",
    "        self.mixture_distns = mixture_distns\n",
    "\n",
    "        assert isinstance(prior_distn, Categorical)\n",
    "        self.prior_distn = prior_distn\n",
    "        \n",
    "        # Initialize the class labels with a \n",
    "        # draw from the prior.\n",
    "        self.Z = npr.choice(prior_distn.pi)\n",
    "        \n",
    "    def resample(self):\n",
    "        \"\"\"\n",
    "        Update Z by sampling from the conditional distribution\n",
    "        of the labels given the mixture distns and the prior distn.\n",
    "        \"\"\"\n",
    "        # TODO: Do this!\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can define a Gaussian mixture model\n",
    "class GaussianMixtureModel(object):\n",
    "    def __init__(self, K, sigmasq, mu_0, etasq_0, alpha):\n",
    "        self.K = K\n",
    "        \n",
    "        # Make the mixture distributions\n",
    "        self.mixture_distns = \\\n",
    "            [Gaussian(sigmasq=sigmasq, mu_0=mu_0, etasq_0=etasq_0) \n",
    "             for _ in range(K)]\n",
    "            \n",
    "        # Make the prior distribution on labels\n",
    "        self.prior_distn = Categorical(alpha=alpha)\n",
    "        \n",
    "        # Make a list for data to be added to\n",
    "        self.labels_list = []\n",
    "        \n",
    "    def add_data(self, X):\n",
    "        self.labels_list.append(\n",
    "            Labels(X, self.K, self.mixture_distns, self.prior_distn))\n",
    "        \n",
    "    def resample_model(self):\n",
    "        # TODO: Run the steps of the Gibbs sampler\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
